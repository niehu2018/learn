A <- matrix( c(1:8,10), nrow = 3, ncol = 3)
A
x = c(1,2,3)
A %*% x
A*x
t(A)
det(A)
diag(A)
solve(A)
A[2,2:ncol(A),drop=FALSE]
x <- list(1:3, TRUE, "Hello", list(1:2, 5))
x
library(MASS)
head(hills)
?apply
A = cbind(1:10, (1:10)^2, (1:10)^3)
A
apply(A, MARGIN = 2, FUN = sum)
hills
apply(hills, MARGIN = 2, mean)
sd(hills)
mean(hills)
apply(hills, MARGIN = 2, FUN = sd)
mu = c(-2,-1,0,1,2)
mu
lapply(mu, function(x) rnor(100, mean = x))
out <- lapply(mu, function(x) rnorm(100, mean = x))
out
sessionInfo()
library(MASS)
head(cabbages)
table(cabbages$Date)
head(Nile)
Nile
plot(Nile, type = "l")
bins = c(0,seq(from=700,to=1300,by=100),Inf)
bins
cut(Nile, bins)
disNile = cut(Nile, bins)
head(disNile)
table(disNile)
?cut
cat('Hello')
cat(57, "clouds", "\n", sep="")
paste("Hello", "world")
LETTERS
nchar("How long is this string")
attributes(hills)
attr(hills,"class")
install.packages('Seurat')
library("seurat")
library("Seurat")
y
install.packages("reticulate")
install.packages("reticulate")
install.packages("reticulate")
library(reticulate)
py_available()
py_available()
py_config()
os <- import(“os”)
plot(sin, -2*pi, 2*pi)
plot(sin, -2*pi)
plot(sin)
?lm
?lm
clear()
clean()
l
fit3 <- lm(weight ~ height + I(height)^2)
fit3 <- lm(weight ~ height + I(height)^2, data = women)
fit3
fit3 <- lm(weight ~ height + I(height^2), data = women)
fit3
fit2 <- lm(weight ~ height + I(height^2), data = women)
summary(fit2)
plot(women$height, women$weight,
xlab = "Height (in inches)",
ylab = "Weight (in lbs)")
lines(women$height, women$weight)
lines(women$height, fitter(fit2))
plot(women$height, women$weight,
xlab = "Height (in inches)",
ylab = "Weight (in lbs)")
lines(women$height, fitter(fit2))
fit2 <- lm(weight ~ height + I(height^2), data = women)
summary(fit2)
plot(women$height, women$weight,
xlab = "Height (in inches)",
ylab = "Weight (in lbs)")
lines(women$height, fitter(fit2))
fit2 <- lm(weight ~ height + I(height^2), data = women)
summary(fit2)
plot(women$height, women$weight,
xlab = "Height (in inches)",
ylab = "Weight (in lbs)")
lines(women$height, fitted(fit2))
scatterplot(weight ~ height, data = women,
spread = FALSE, lty.smooth = 2, pch = 19,
main = "Women Age 30 ~ 39",
xlab = "Height (inches)",
ylab = "Weight (lbs)")
library(car)
install.packages("car")
# car包中的scatterplot()函数
# 它可以很容易、方便地绘制二元关系
library(car)
scatterplot(weight ~ height, data = women,
spread = FALSE, lty.smooth = 2, pch = 19,
main = "Women Age 30 ~ 39",
xlab = "Height (inches)",
ylab = "Weight (lbs)")
?scatterplot
scatterplot(weight ~ height, data = women,
spread = FALSE, lty.smooth = 2, pch = 19,
main = "Women Age 30 ~ 39",
xlab = "Height (inches)",
ylab = "Weight (lbs)")
warnings()
scatterplot(weight ~ height, data = women,
spread = FALSE, pch = 19,
main = "Women Age 30 ~ 39",
xlab = "Height (inches)",
ylab = "Weight (lbs)")
scatterplot(weight ~ height, data = women,
pch = 19,
main = "Women Age 30 ~ 39",
xlab = "Height (inches)",
ylab = "Weight (lbs)")
?scatterplot
scatterplot(weight ~ height, data = women,
pch = 19, spread = FALSE,
main = "Women Age 30 ~ 39",
xlab = "Height (inches)",
ylab = "Weight (lbs)")
scatterplot(weight ~ height, data = women,
pch = 19, spread = FALSE,
main = "Women Age 30 ~ 39",
xlab = "Height (inches)",
ylab = "Weight (lbs)")
?scatterplot
scatterplot(weight ~ height, data = women,
pch = 19,
main = "Women Age 30 ~ 39",
xlab = "Height (inches)",
ylab = "Weight (lbs)")
scatterplot(weight ~ height, data = women,
pch = 19,
main = "Women Age 30 ~ 39",
xlab = "Height (inches)",
ylab = "Weight (lbs)")
?scatterplot
# 回归诊断
fit <- lm(weight ~ height, data = women)
par(mfrow=c(2,2))
plot(fit)
fit2 <- lm(weight ~ height + I(height^2), data = women)
par(mfrow=c(2,2))
plot(fit2)
# 回归诊断
# 1.标准方法：四幅图, 从图形可以鉴别出离群点、高杠杆值点和强影响点
fit <- lm(weight ~ height, data = women)
par(mfrow=c(2,2))
plot(fit)
# 回归诊断
# 1.标准方法：四幅图, 从图形可以鉴别出离群点、高杠杆值点和强影响点
# 1 => Resudulas vs Fitted 残差图与拟合图, 暗示着你可能需要对回归模型加上一个二次项
# 2 => Normal Q-Q, 正态Q-Q图(Normal Q-Q，右上)是在正态分布对应的值下，标准化残差的概率图
# 3 => Scale-Location, 位置尺度图, 评价是否不变方差
# 4 => Residuals vs Leverage, 残差与杠杆图, 从图形可以鉴别出离群点、高杠杆值点和强影响点
fit <- lm(weight ~ height, data = women)
confint(fit)
# 回归诊断
# 1.标准方法：四幅图, 从图形可以鉴别出离群点、高杠杆值点和强影响点
# 1 => Resudulas vs Fitted 残差图与拟合图, 暗示着你可能需要对回归模型加上一个二次项
# 2 => Normal Q-Q, 正态Q-Q图(Normal Q-Q，右上)是在正态分布对应的值下，标准化残差的概率图
# 3 => Scale-Location, 位置尺度图, 评价是否不变方差
# 4 => Residuals vs Leverage, 残差与杠杆图, 从图形可以鉴别出离群点、高杠杆值点和强影响点
fit <- lm(weight ~ height, data = women)
par(mfrow=c(2,2))
plot(fit)
seq(0,130,10)
install.packages("sva")
BiocManager::install("sva")
BiocManager::install("limmaGUI")
BiocManager::install("batchelor")
BiocManager::install("scran")
library("Seurat")
?Convert
sessionInfo()
?Convert
Seurat::Convert
?Seurat::Convert
Seurat::Convert
library(scater)
library(Seurat)
library(cowplot)
?Convert
??convert
scater::Convert
?Convert.SingleCellExperiment
??Convert.SingleCellExperiment
? as.Seurat
? as.Seurat
library(scRNAseq)
sce <- GrunPancreasData()
sce
sce <- GrunPancreasData()
sce <- GrunPancreasData()
seurat <- as.Seurat(sce)
?as.Seurat
sce
sce <- logcounts(sce)
logcounts(sce)
logcounts(counts(sce))
log(sce)
log(counts(sce))
logcounts(sce)
assays(sce)
sce <- scater::logNormCounts(sce)
library(scater)
sce <- scater::logNormCounts(sce)
?scater::logNormCounts
library(scran)
library(scater)
clusters <- quickCluster(sce)
assays(sce)
clusters <- quickCluster(sce)
library(scran)
clusters <- quickCluster(sce)
sce <- GrunPancreasData()
assays(sce)
clusters <- quickCluster(sce)
?quickCluster
sce
sce <- computeSumFactors(sce, clusters=clusters)
sce <- logNormCounts(sce)
sce <- logNormCounts(sce)
library(dplyr)
library(ggplot2)
library(harmony)
library(cowplot)
colors_use <- c(`jurkat` = '#810F7C', `t293` = '#D09E2D',`half` = '#006D2C')
# use scatter to do umap
do_scatter <- function(umap_use, meta_data, label_name, no_guides = TRUE,
do_labels = TRUE, nice_names,
palette_use = colors_use,
pt_size = 4, point_size = .5, base_size = 12,
do_points = TRUE, do_density = FALSE, h = 6, w = 8) {
umap_use <- umap_use[, 1:2]
colnames(umap_use) <- c('X1', 'X2')
plt_df <- umap_use %>% data.frame() %>%
cbind(meta_data) %>%
dplyr::sample_frac(1L)
plt_df$given_name <- plt_df[[label_name]]
if (!missing(nice_names)) {
plt_df %<>%
dplyr::inner_join(nice_names, by = "given_name") %>%
subset(nice_name != "" & !is.na(nice_name))
plt_df[[label_name]] <- plt_df$nice_name
}
plt <- plt_df %>%
ggplot(aes_string("X1", "X2", col = label_name, fill = label_name)) +
theme_test(base_size = base_size) +
theme(panel.background = element_rect(fill = NA, color = "black")) +
guides(color = guide_legend(override.aes = list(stroke = 1, alpha = 1,
shape = 16, size = 4)),
alpha = FALSE) +
scale_color_manual(values = palette_use) +
scale_fill_manual(values = palette_use) +
theme(plot.title = element_text(hjust = .5)) +
labs(x = "PC 1", y = "PC 2")
if (do_points)
plt <- plt + geom_point(shape = '.')
if (do_density)
plt <- plt + geom_density_2d()
if (no_guides)
plt <- plt + guides(col = FALSE, fill = FALSE, alpha = FALSE)
if (do_labels) {
data_labels <- plt_df %>%
dplyr::group_by_(label_name) %>%
dplyr::summarise(X1 = mean(X1), X2 = mean(X2)) %>%
dplyr::ungroup()
plt <- plt + geom_label(data = data_labels, label.size = NA,
aes_string(label = label_name),
color = "white", size = pt_size, alpha = 1,
segment.size = 0) +
guides(col = FALSE, fill = FALSE)
}
return(plt)
}
data(cell_lines)
V <- cell_lines$scaled_pcs
meta_data <- cell_lines$meta_data
# Before remove batch effect
p1 <- do_scatter(V, meta_data, 'dataset') +
labs(title = 'Colored by dataset')
p2 <- do_scatter(V, meta_data, 'cell_type') +
labs(title = 'Colored by cell type')
cowplot::plot_grid(p1, p2)
# Remove batch effect using harmony
harmony_embeddings <- harmony::HarmonyMatrix(
V, meta_data, 'dataset', do_pca = FALSE, verbose=FALSE
)
# After remove batch effect
p1 <- do_scatter(harmony_embeddings, meta_data, 'dataset') +
labs(title = 'Colored by dataset')
p2 <- do_scatter(harmony_embeddings, meta_data, 'cell_type') +
labs(title = 'Colored by cell type')
cowplot::plot_grid(p1, p2, nrow = 1)
meta_data
?harmony::HarmonyMatrix
colnames(cell_lines)
cell_lines
colnames(V)
ibrary(Seurat)
library(SeuratData)
library(cowplot)
library(patchwork)
install.packages("SeuratData")
install.packages("patchwork")
install.packages("patchwork")
devtools::install_github('satijalab/seurat-data')
devtools::install_github('satijalab/seurat-data')
# Setup the Seurat objects
ibrary(Seurat)
# Setup the Seurat objects
library(Seurat)
library(SeuratData)
library(cowplot)
library(patchwork)
InstallData("ifnb")
library(devtools)
devtools::install_github('satijalab/seurat-data')
devtools::install_github('satijalab/seurat-data')
install_github("satijalab/seurat-data")
install_github("https://github.com/satijalab/seurat-data.git")
install_github("satijalab/seurat-data")
install.packages("~/Downloads/seurat-data-master.tar.gz", repos = NULL, type = "source")
# Setup the Seurat objects
library(Seurat)
library(SeuratData)
library(cowplot)
library(patchwork)
InstallData("ifnb")
# load data
data("ifnb")
ifnb.list <- SplitObject(ifnb, split.by = "stim")
ifnb.list <- lapply(X = ifnb.list, FUN = function(x) {
x <- NormalizeData(x)
x <- FindVariableFeatures(x, selection.method = "vst", nfeatures = 2000)
})
ifnb.list
# Perform integration
immune.anchors  <- FindIntegrationAnchors(object.list = ifnb.list, dims = 1:20)
immune.combined <- IntegrateData(anchorset = immune.anchors, dims = 1:20)
# Perform an integrated analysis
DefaultAssay(immune.combined) <- "integrated"
# Run the standard workflow for visualization and clustering
immune.combined <- ScaleData(immune.combined, verbose = FALSE)
immune.combined <- RunPCA(immune.combined, npcs = 30, verbose = FALSE)
# t-SNE and Clustering
immune.combined <- RunUMAP(immune.combined, reduction = "pca", dims = 1:20)
immune.combined <- FindNeighbors(immune.combined, reduction = "pca", dims = 1:20)
immune.combined <- FindClusters(immune.combined, resolution = 0.5)
# Visualization
p1 <- DimPlot(immune.combined, reduction = "umap", group.by = "stim")
p2 <- DimPlot(immune.combined, reduction = "umap", label = TRUE)
plot_grid(p1, p2)
load('download/pbmc_stim.RData')
load('/Users/niehu/Downloads/pbmc_stim.RData')
pbmc <- CreateSeuratObject(counts = cbind(stim.sparse, ctrl.sparse), project = "PBMC", min.cells = 5) %>%
Seurat::NormalizeData(verbose = FALSE) %>%
FindVariableFeatures(selection.method = "vst", nfeatures = 2000) %>%
ScaleData(verbose = FALSE) %>%
RunPCA(pc.genes = pbmc@var.genes, npcs = 20, verbose = FALSE)
pbmc@meta.data$stim <- c(rep("STIM", ncol(stim.sparse)), rep("CTRL", ncol(ctrl.sparse)))
p1 <- DimPlot(object = pbmc, reduction = "pca", pt.size = .1, group.by = "stim", do.return = TRUE)
p2 <- VlnPlot(object = pbmc, features = "PC_1", group.by = "stim", do.return = TRUE, pt.size = .1)
plot_grid(p1,p2)
pbmc@meta.data$stim <- c(rep("STIM", ncol(stim.sparse)), rep("CTRL", ncol(ctrl.sparse)))
p1 <- DimPlot(object = pbmc, reduction = "pca", pt.size = .1, group.by = "stim", do.return = TRUE)
p1 <- DimPlot(object = pbmc, reduction = "pca", pt.size = .1, group.by = "stim")
p2 <- VlnPlot(object = pbmc, features = "PC_1", group.by = "stim",pt.size = .1)
plot_grid(p1,p2)
p1 <- DimPlot(object = pbmc, reduction = "pca", pt.size = .1, group.by = "stim")
p2 <- VlnPlot(object = pbmc, features = "PC_1", group.by = "stim",pt.size = .1)
plot_grid(p1,p2)
options(repr.plot.height = 2.5, repr.plot.width = 6)
pbmc <- pbmc %>% RunHarmony("stim", plot_convergence = TRUE)
harmony_embeddings <- Embeddings(pbmc, 'harmony')
harmony_embeddings[1:5, 1:5]
options(repr.plot.height = 5, repr.plot.width = 12)
p1 <- DimPlot(object = pbmc, reduction = "harmony", pt.size = .1, group.by = "stim", do.return = TRUE)
p2 <- VlnPlot(object = pbmc, features = "harmony_1", group.by = "stim", do.return = TRUE, pt.size = .1)
options(repr.plot.height = 5, repr.plot.width = 12)
p1 <- DimPlot(object = pbmc, reduction = "harmony", pt.size = .1, group.by = "stim", do.return = TRUE)
p2 <- VlnPlot(object = pbmc, features = "harmony_1", group.by = "stim", do.return = TRUE, pt.size = .1)
plot_grid(p1,p2)
p1 <- DimPlot(object = pbmc, reduction = "harmony", pt.size = .1, group.by = "stim")
p2 <- VlnPlot(object = pbmc, features = "harmony_1", group.by = "stim"pt.size = .1)
p1 <- DimPlot(object = pbmc, reduction = "harmony", pt.size = .1, group.by = "stim")
p2 <- VlnPlot(object = pbmc, features = "harmony_1", group.by = "stim",pt.size = .1)
plot_grid(p1,p2)
pbmc <- pbmc %>%
RunUMAP(reduction = "harmony", dims = 1:20) %>%
FindNeighbors(reduction = "harmony", dims = 1:20) %>%
FindClusters(resolution = 0.5) %>%
identity()
options(repr.plot.height = 4, repr.plot.width = 10)
options(repr.plot.height = 4, repr.plot.width = 10)
DimPlot(pbmc, reduction = "umap", group.by = "stim", pt.size = .1, split.by = 'stim')
options(repr.plot.height = 4, repr.plot.width = 6)
DimPlot(pbmc, reduction = "umap", label = TRUE, pt.size = .1)
load('/Users/niehu/Downloads/pbmc_stim.RData')
pbmc <- CreateSeuratObject(counts = cbind(stim.sparse, ctrl.sparse), project = "PBMC", min.cells = 5) %>%
Seurat::NormalizeData(verbose = FALSE) %>%
FindVariableFeatures(selection.method = "vst", nfeatures = 2000) %>%
ScaleData(verbose = FALSE) %>%
RunPCA(pc.genes = pbmc@var.genes, npcs = 20, verbose = FALSE)
# Setup the Seurat objects
library(Seurat)
library(SeuratData)
library(cowplot)
library(patchwork)
ifnb
ifnb@assays$RNA
head(ifnb@assays$RNA)
class(ifnb@assays$RNA)
ifnb@assays$RNA@counts
data.frame(ifnb@assays$RNA@counts)
ifnb@assays$RNA@counts
as.matrix(ifnb@assays$RNA@counts)
devtools::install_github("sqjin/CellChat")
devtools::install_github("sqjin/CellChat")
devtools::install_local
?devtools::install_local
?devtools::install_local("/Users/niehu/Downloads/CellChat-master.zip")
devtools::install_local("/Users/niehu/Downloads/CellChat-master.zip")
devtools::install_github("sqjin/CellChat", host = "https://api.github.com")
library(CellChat)
devtools::install_github("sqjin/NMF")
devtools::install_github("sqjin/NMF", host = "https://api.github.com")
devtools::install_github("sqjin/NMF", host = "https://api.github.com")
devtools::install_github("jokergoo/ComplexHeatmap",host = "https://api.github.com")
devtools::install_github("sqjin/NMF")
library(CellChat)
devtools::install_github("sqjin/NMF", host = "https://api.github.com")
devtools::install_github("jokergoo/ComplexHeatmap",host = "https://api.github.com")
devtools::install_github("sqjin/CellChat", host = "https://api.github.com")
devtools::install_github("sqjin/NMF", host = "https://api.github.com")
devtools::install_github("jokergoo/ComplexHeatmap",host = "https://api.github.com")
devtools::install_github("sqjin/CellChat", host = "https://api.github.com")
install.packages("pdftools")
library(pdftools)
# extract some pages
pdf_subset('https://cran.r-project.org/doc/manuals/r-release/R-intro.pdf',
pages = 1:3, output = "subset.pdf")
# Should say 3
pdf_length("subset.pdf")
getwd()
pdf("test.pdf")
plot(mtcars)
dev.off()
# Combine them with the other one
pdf_combine(c("test.pdf", "subset.pdf"), output = "joined.pdf")
# Should say 4
pdf_length("joined.pdf")
pdf("myOut.pdf")
for (i in 1:10){
plot(rnorm(10))
}
dev.off()
install.packages("shiny")
# install.packages("shiny")
library(shiny)
# install.packages("shiny")
install.packages("datasets")
setwd("/Users/niehu/Desktop/empty_shiny/shiny")
library(shiny)
l
runApp("/Users/niehu/Desktop/empty_shiny/shiny")
runApp("/Users/niehu/Desktop/empty_shiny/shiny")
runApp()
runApp()
runApp('~/Desktop/empty_shiny/shiny')
runApp('/Users/niehu/Documents/GitHub/learn/learn_shiny/empty_shiny/shiny')
runApp('/Users/niehu/Documents/GitHub/learn/learn_shiny/empty_shiny/shiny')
runApp('/Users/niehu/Documents/GitHub/learn/learn_shiny/empty_shiny/shiny')
setwd("/Users/niehu/Desktop/lession2")
runApp('lesson2.R')
runApp('lesson2.R')
runApp('lesson2.R')
runApp('lesson2.R')
runApp('lesson2.R')
runApp('lesson2.R')
runApp('lesson2.R')
runApp('lesson2.R')
runApp('lesson2.R')
gtwd()
getwd()
runApp('lesson2.R')
runApp('lesson2.R')
runApp('lesson2.R')
runApp('lesson2.R')
runApp('lesson2.R')
runApp('lesson2-2.R')
runApp('lesson2.R')
runApp('lesson2-2.R')
runApp('lesson2-2.R')
setwd("/Users/niehu/Desktop/lesson3")
runApp('lesson3-1.R')
